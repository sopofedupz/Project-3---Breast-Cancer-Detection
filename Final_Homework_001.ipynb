{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/Resources'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 3,
=======
   "execution_count": 2,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Resources/data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= data['diagnosis'].map({'M':0,'B':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "564    0\n",
       "565    0\n",
       "566    0\n",
       "567    0\n",
       "568    1\n",
       "Name: diagnosis, Length: 569, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= data.drop(columns=['id','diagnosis','Unnamed: 32'])\n",
    "x1= data.drop(columns=['id','diagnosis','Unnamed: 32'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  class  \n",
       "0                  0.2654          0.4601                  0.11890      0  \n",
       "1                  0.1860          0.2750                  0.08902      0  \n",
       "2                  0.2430          0.3613                  0.08758      0  \n",
       "3                  0.2575          0.6638                  0.17300      0  \n",
       "4                  0.1625          0.2364                  0.07678      0  \n",
       "..                    ...             ...                      ...    ...  \n",
       "564                0.2216          0.2060                  0.07115      0  \n",
       "565                0.1628          0.2572                  0.06637      0  \n",
       "566                0.1418          0.2218                  0.07820      0  \n",
       "567                0.2650          0.4087                  0.12400      0  \n",
       "568                0.0000          0.2871                  0.07039      1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.33)\n",
    "N ,D =X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalling the data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now creating the model\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Input(shape=(D,)),\n",
    "                                    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can avoid this error by converting your labels to arrays before calling model.fit()\n",
    "X_train = np.asarray(X_train)\n",
    "Y_train = np.asarray(Y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "Y_test = np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 381 samples, validate on 188 samples\n",
      "Epoch 1/100\n",
      "381/381 [==============================] - 1s 2ms/sample - loss: 0.3436 - accuracy: 0.9108 - val_loss: 0.3176 - val_accuracy: 0.8830\n",
      "Epoch 2/100\n",
      "381/381 [==============================] - 0s 145us/sample - loss: 0.3196 - accuracy: 0.9108 - val_loss: 0.2949 - val_accuracy: 0.8989\n",
      "Epoch 3/100\n",
      "381/381 [==============================] - 0s 146us/sample - loss: 0.2987 - accuracy: 0.9213 - val_loss: 0.2764 - val_accuracy: 0.8989\n",
      "Epoch 4/100\n",
      "381/381 [==============================] - 0s 143us/sample - loss: 0.2819 - accuracy: 0.9213 - val_loss: 0.2607 - val_accuracy: 0.8989\n",
      "Epoch 5/100\n",
      "381/381 [==============================] - 0s 145us/sample - loss: 0.2676 - accuracy: 0.9239 - val_loss: 0.2475 - val_accuracy: 0.9043\n",
      "Epoch 6/100\n",
      "381/381 [==============================] - 0s 147us/sample - loss: 0.2557 - accuracy: 0.9291 - val_loss: 0.2358 - val_accuracy: 0.9096\n",
      "Epoch 7/100\n",
      "381/381 [==============================] - 0s 142us/sample - loss: 0.2449 - accuracy: 0.9265 - val_loss: 0.2259 - val_accuracy: 0.9096\n",
      "Epoch 8/100\n",
      "381/381 [==============================] - 0s 138us/sample - loss: 0.2358 - accuracy: 0.9265 - val_loss: 0.2169 - val_accuracy: 0.9096\n",
      "Epoch 9/100\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.2274 - accuracy: 0.9213 - val_loss: 0.2091 - val_accuracy: 0.9096\n",
      "Epoch 10/100\n",
      "381/381 [==============================] - 0s 146us/sample - loss: 0.2200 - accuracy: 0.9239 - val_loss: 0.2020 - val_accuracy: 0.9149\n",
      "Epoch 11/100\n",
      "381/381 [==============================] - 0s 146us/sample - loss: 0.2133 - accuracy: 0.9239 - val_loss: 0.1954 - val_accuracy: 0.9202\n",
      "Epoch 12/100\n",
      "381/381 [==============================] - 0s 142us/sample - loss: 0.2071 - accuracy: 0.9239 - val_loss: 0.1894 - val_accuracy: 0.9255\n",
      "Epoch 13/100\n",
      "381/381 [==============================] - 0s 142us/sample - loss: 0.2014 - accuracy: 0.9239 - val_loss: 0.1840 - val_accuracy: 0.9255\n",
      "Epoch 14/100\n",
      "381/381 [==============================] - 0s 139us/sample - loss: 0.1962 - accuracy: 0.9291 - val_loss: 0.1790 - val_accuracy: 0.9309\n",
      "Epoch 15/100\n",
      "381/381 [==============================] - 0s 141us/sample - loss: 0.1915 - accuracy: 0.9318 - val_loss: 0.1745 - val_accuracy: 0.9362\n",
      "Epoch 16/100\n",
      "381/381 [==============================] - 0s 141us/sample - loss: 0.1871 - accuracy: 0.9344 - val_loss: 0.1701 - val_accuracy: 0.9362\n",
      "Epoch 17/100\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.1828 - accuracy: 0.9344 - val_loss: 0.1663 - val_accuracy: 0.9362\n",
      "Epoch 18/100\n",
      "381/381 [==============================] - 0s 137us/sample - loss: 0.1790 - accuracy: 0.9344 - val_loss: 0.1625 - val_accuracy: 0.9362\n",
      "Epoch 19/100\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.1754 - accuracy: 0.9370 - val_loss: 0.1589 - val_accuracy: 0.9415\n",
      "Epoch 20/100\n",
      "381/381 [==============================] - 0s 135us/sample - loss: 0.1718 - accuracy: 0.9396 - val_loss: 0.1558 - val_accuracy: 0.9415\n",
      "Epoch 21/100\n",
      "381/381 [==============================] - 0s 139us/sample - loss: 0.1687 - accuracy: 0.9396 - val_loss: 0.1529 - val_accuracy: 0.9468\n",
      "Epoch 22/100\n",
      "381/381 [==============================] - 0s 147us/sample - loss: 0.1656 - accuracy: 0.9396 - val_loss: 0.1500 - val_accuracy: 0.9468\n",
      "Epoch 23/100\n",
      "381/381 [==============================] - 0s 137us/sample - loss: 0.1628 - accuracy: 0.9396 - val_loss: 0.1474 - val_accuracy: 0.9468\n",
      "Epoch 24/100\n",
      "381/381 [==============================] - 0s 137us/sample - loss: 0.1602 - accuracy: 0.9423 - val_loss: 0.1447 - val_accuracy: 0.9468\n",
      "Epoch 25/100\n",
      "381/381 [==============================] - 0s 138us/sample - loss: 0.1575 - accuracy: 0.9423 - val_loss: 0.1423 - val_accuracy: 0.9468\n",
      "Epoch 26/100\n",
      "381/381 [==============================] - 0s 135us/sample - loss: 0.1551 - accuracy: 0.9423 - val_loss: 0.1401 - val_accuracy: 0.9468\n",
      "Epoch 27/100\n",
      "381/381 [==============================] - 0s 143us/sample - loss: 0.1527 - accuracy: 0.9475 - val_loss: 0.1381 - val_accuracy: 0.9468\n",
      "Epoch 28/100\n",
      "381/381 [==============================] - 0s 141us/sample - loss: 0.1506 - accuracy: 0.9475 - val_loss: 0.1361 - val_accuracy: 0.9468\n",
      "Epoch 29/100\n",
      "381/381 [==============================] - 0s 144us/sample - loss: 0.1484 - accuracy: 0.9475 - val_loss: 0.1343 - val_accuracy: 0.9468\n",
      "Epoch 30/100\n",
      "381/381 [==============================] - 0s 137us/sample - loss: 0.1465 - accuracy: 0.9501 - val_loss: 0.1324 - val_accuracy: 0.9468\n",
      "Epoch 31/100\n",
      "381/381 [==============================] - 0s 139us/sample - loss: 0.1444 - accuracy: 0.9501 - val_loss: 0.1308 - val_accuracy: 0.9468\n",
      "Epoch 32/100\n",
      "381/381 [==============================] - 0s 138us/sample - loss: 0.1426 - accuracy: 0.9501 - val_loss: 0.1291 - val_accuracy: 0.9468\n",
      "Epoch 33/100\n",
      "381/381 [==============================] - 0s 138us/sample - loss: 0.1409 - accuracy: 0.9528 - val_loss: 0.1275 - val_accuracy: 0.9468\n",
      "Epoch 34/100\n",
      "381/381 [==============================] - 0s 142us/sample - loss: 0.1391 - accuracy: 0.9528 - val_loss: 0.1261 - val_accuracy: 0.9468\n",
      "Epoch 35/100\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.1375 - accuracy: 0.9528 - val_loss: 0.1248 - val_accuracy: 0.9468\n",
      "Epoch 36/100\n",
      "381/381 [==============================] - 0s 139us/sample - loss: 0.1360 - accuracy: 0.9528 - val_loss: 0.1233 - val_accuracy: 0.9468\n",
      "Epoch 37/100\n",
      "381/381 [==============================] - 0s 142us/sample - loss: 0.1345 - accuracy: 0.9528 - val_loss: 0.1220 - val_accuracy: 0.9468\n",
      "Epoch 38/100\n",
      "381/381 [==============================] - 0s 141us/sample - loss: 0.1331 - accuracy: 0.9528 - val_loss: 0.1209 - val_accuracy: 0.9468\n",
      "Epoch 39/100\n",
      "381/381 [==============================] - 0s 140us/sample - loss: 0.1316 - accuracy: 0.9528 - val_loss: 0.1197 - val_accuracy: 0.9468\n",
      "Epoch 40/100\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.1302 - accuracy: 0.9528 - val_loss: 0.1185 - val_accuracy: 0.9468\n",
      "Epoch 41/100\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.1289 - accuracy: 0.9528 - val_loss: 0.1175 - val_accuracy: 0.9468\n",
      "Epoch 42/100\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.1277 - accuracy: 0.9528 - val_loss: 0.1166 - val_accuracy: 0.9468\n",
      "Epoch 43/100\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.1264 - accuracy: 0.9528 - val_loss: 0.1155 - val_accuracy: 0.9468\n",
      "Epoch 44/100\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.1252 - accuracy: 0.9554 - val_loss: 0.1146 - val_accuracy: 0.9521\n",
      "Epoch 45/100\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.1241 - accuracy: 0.9554 - val_loss: 0.1135 - val_accuracy: 0.9521\n",
      "Epoch 46/100\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.1230 - accuracy: 0.9554 - val_loss: 0.1126 - val_accuracy: 0.9521\n",
      "Epoch 47/100\n",
      "381/381 [==============================] - 0s 140us/sample - loss: 0.1219 - accuracy: 0.9580 - val_loss: 0.1119 - val_accuracy: 0.9521\n",
      "Epoch 48/100\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.1208 - accuracy: 0.9580 - val_loss: 0.1111 - val_accuracy: 0.9521\n",
      "Epoch 49/100\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.1199 - accuracy: 0.9580 - val_loss: 0.1102 - val_accuracy: 0.9521\n",
      "Epoch 50/100\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.1189 - accuracy: 0.9580 - val_loss: 0.1094 - val_accuracy: 0.9521\n",
      "Epoch 51/100\n",
      "381/381 [==============================] - 0s 138us/sample - loss: 0.1179 - accuracy: 0.9580 - val_loss: 0.1087 - val_accuracy: 0.9574\n",
      "Epoch 52/100\n",
      "381/381 [==============================] - 0s 142us/sample - loss: 0.1170 - accuracy: 0.9580 - val_loss: 0.1079 - val_accuracy: 0.9574\n",
      "Epoch 53/100\n",
      "381/381 [==============================] - 0s 140us/sample - loss: 0.1161 - accuracy: 0.9580 - val_loss: 0.1073 - val_accuracy: 0.9574\n",
      "Epoch 54/100\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.1152 - accuracy: 0.9580 - val_loss: 0.1067 - val_accuracy: 0.9574\n",
      "Epoch 55/100\n",
<<<<<<< Updated upstream
      "381/381 [==============================] - 0s 152us/sample - loss: 0.1534 - accuracy: 0.9606 - val_loss: 0.1691 - val_accuracy: 0.9362\n",
      "Epoch 56/100\n",
      "381/381 [==============================] - 0s 151us/sample - loss: 0.1514 - accuracy: 0.9606 - val_loss: 0.1675 - val_accuracy: 0.9362\n",
=======
      "381/381 [==============================] - 0s 136us/sample - loss: 0.1144 - accuracy: 0.9580 - val_loss: 0.1060 - val_accuracy: 0.9574\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 0s 135us/sample - loss: 0.1135 - accuracy: 0.9606 - val_loss: 0.1053 - val_accuracy: 0.9574\n",
>>>>>>> Stashed changes
      "Epoch 57/100\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.1127 - accuracy: 0.9606 - val_loss: 0.1047 - val_accuracy: 0.9574\n",
      "Epoch 58/100\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.1119 - accuracy: 0.9606 - val_loss: 0.1043 - val_accuracy: 0.9574\n",
      "Epoch 59/100\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.1112 - accuracy: 0.9606 - val_loss: 0.1036 - val_accuracy: 0.9574\n",
      "Epoch 60/100\n",
      "381/381 [==============================] - 0s 138us/sample - loss: 0.1104 - accuracy: 0.9606 - val_loss: 0.1030 - val_accuracy: 0.9574\n",
      "Epoch 61/100\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.1097 - accuracy: 0.9606 - val_loss: 0.1026 - val_accuracy: 0.9574\n",
      "Epoch 62/100\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.1090 - accuracy: 0.9606 - val_loss: 0.1020 - val_accuracy: 0.9574\n",
      "Epoch 63/100\n",
      "381/381 [==============================] - 0s 131us/sample - loss: 0.1083 - accuracy: 0.9606 - val_loss: 0.1015 - val_accuracy: 0.9574\n",
      "Epoch 64/100\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.1076 - accuracy: 0.9606 - val_loss: 0.1012 - val_accuracy: 0.9628\n",
      "Epoch 65/100\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.1070 - accuracy: 0.9606 - val_loss: 0.1006 - val_accuracy: 0.9628\n",
      "Epoch 66/100\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.1063 - accuracy: 0.9606 - val_loss: 0.1002 - val_accuracy: 0.9628\n",
      "Epoch 67/100\n",
      "381/381 [==============================] - 0s 140us/sample - loss: 0.1057 - accuracy: 0.9606 - val_loss: 0.0997 - val_accuracy: 0.9628\n",
      "Epoch 68/100\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.1050 - accuracy: 0.9606 - val_loss: 0.0993 - val_accuracy: 0.9628\n",
      "Epoch 69/100\n",
      "381/381 [==============================] - 0s 138us/sample - loss: 0.1045 - accuracy: 0.9606 - val_loss: 0.0988 - val_accuracy: 0.9628\n",
      "Epoch 70/100\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.1040 - accuracy: 0.9633 - val_loss: 0.0985 - val_accuracy: 0.9628\n",
      "Epoch 71/100\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.1033 - accuracy: 0.9633 - val_loss: 0.0981 - val_accuracy: 0.9628\n",
      "Epoch 72/100\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.1028 - accuracy: 0.9633 - val_loss: 0.0978 - val_accuracy: 0.9628\n",
      "Epoch 73/100\n",
      "381/381 [==============================] - 0s 143us/sample - loss: 0.1022 - accuracy: 0.9633 - val_loss: 0.0973 - val_accuracy: 0.9628\n",
      "Epoch 74/100\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.1017 - accuracy: 0.9633 - val_loss: 0.0970 - val_accuracy: 0.9628\n",
      "Epoch 75/100\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.1011 - accuracy: 0.9659 - val_loss: 0.0965 - val_accuracy: 0.9628\n",
      "Epoch 76/100\n",
      "381/381 [==============================] - 0s 137us/sample - loss: 0.1006 - accuracy: 0.9711 - val_loss: 0.0961 - val_accuracy: 0.9628\n",
      "Epoch 77/100\n",
      "381/381 [==============================] - 0s 135us/sample - loss: 0.1001 - accuracy: 0.9738 - val_loss: 0.0957 - val_accuracy: 0.9628\n",
      "Epoch 78/100\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.0996 - accuracy: 0.9738 - val_loss: 0.0954 - val_accuracy: 0.9628\n",
      "Epoch 79/100\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.0991 - accuracy: 0.9738 - val_loss: 0.0952 - val_accuracy: 0.9628\n",
      "Epoch 80/100\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.0987 - accuracy: 0.9738 - val_loss: 0.0947 - val_accuracy: 0.9628\n",
      "Epoch 81/100\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.0982 - accuracy: 0.9738 - val_loss: 0.0945 - val_accuracy: 0.9628\n",
      "Epoch 82/100\n",
      "381/381 [==============================] - 0s 130us/sample - loss: 0.0977 - accuracy: 0.9738 - val_loss: 0.0942 - val_accuracy: 0.9628\n",
      "Epoch 83/100\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.0973 - accuracy: 0.9738 - val_loss: 0.0938 - val_accuracy: 0.9628\n",
      "Epoch 84/100\n",
      "381/381 [==============================] - 0s 132us/sample - loss: 0.0968 - accuracy: 0.9738 - val_loss: 0.0935 - val_accuracy: 0.9628\n",
      "Epoch 85/100\n",
      "381/381 [==============================] - 0s 138us/sample - loss: 0.0965 - accuracy: 0.9738 - val_loss: 0.0933 - val_accuracy: 0.9628\n",
      "Epoch 86/100\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.0960 - accuracy: 0.9738 - val_loss: 0.0930 - val_accuracy: 0.9628\n",
      "Epoch 87/100\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.0956 - accuracy: 0.9738 - val_loss: 0.0927 - val_accuracy: 0.9628\n",
      "Epoch 88/100\n",
      "381/381 [==============================] - 0s 139us/sample - loss: 0.0952 - accuracy: 0.9790 - val_loss: 0.0924 - val_accuracy: 0.9628\n",
      "Epoch 89/100\n",
      "381/381 [==============================] - 0s 135us/sample - loss: 0.0948 - accuracy: 0.9790 - val_loss: 0.0922 - val_accuracy: 0.9628\n",
      "Epoch 90/100\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.0944 - accuracy: 0.9790 - val_loss: 0.0921 - val_accuracy: 0.9628\n",
      "Epoch 91/100\n",
      "381/381 [==============================] - 0s 135us/sample - loss: 0.0940 - accuracy: 0.9790 - val_loss: 0.0918 - val_accuracy: 0.9628\n",
      "Epoch 92/100\n",
      "381/381 [==============================] - 0s 135us/sample - loss: 0.0937 - accuracy: 0.9790 - val_loss: 0.0916 - val_accuracy: 0.9628\n",
      "Epoch 93/100\n",
      "381/381 [==============================] - 0s 137us/sample - loss: 0.0933 - accuracy: 0.9790 - val_loss: 0.0913 - val_accuracy: 0.9628\n",
      "Epoch 94/100\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.0929 - accuracy: 0.9790 - val_loss: 0.0909 - val_accuracy: 0.9628\n",
      "Epoch 95/100\n",
      "381/381 [==============================] - 0s 136us/sample - loss: 0.0926 - accuracy: 0.9790 - val_loss: 0.0907 - val_accuracy: 0.9628\n",
      "Epoch 96/100\n",
      "381/381 [==============================] - 0s 140us/sample - loss: 0.0922 - accuracy: 0.9790 - val_loss: 0.0905 - val_accuracy: 0.9628\n",
      "Epoch 97/100\n",
      "381/381 [==============================] - 0s 133us/sample - loss: 0.0919 - accuracy: 0.9790 - val_loss: 0.0902 - val_accuracy: 0.9628\n",
      "Epoch 98/100\n",
      "381/381 [==============================] - 0s 135us/sample - loss: 0.0915 - accuracy: 0.9790 - val_loss: 0.0899 - val_accuracy: 0.9628\n",
      "Epoch 99/100\n",
      "381/381 [==============================] - 0s 135us/sample - loss: 0.0912 - accuracy: 0.9790 - val_loss: 0.0897 - val_accuracy: 0.9628\n",
      "Epoch 100/100\n",
      "381/381 [==============================] - 0s 134us/sample - loss: 0.0909 - accuracy: 0.9790 - val_loss: 0.0894 - val_accuracy: 0.9628\n"
     ]
    }
   ],
   "source": [
    "r= model.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "381/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 29us/sample - loss: 0.0665 - accuracy: 0.9790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score [0.09064408958818657, 0.9790026]\n",
      "188/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 36us/sample - loss: 0.0682 - accuracy: 0.9628\n",
      "Test score [0.0894432396013686, 0.96276593]\n"
     ]
    }
   ],
   "source": [
    "# train and test score\n",
    "print(\"Train score\",model.evaluate(X_train,Y_train))\n",
    "print(\"Test score\",model.evaluate(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'],label='loss')\n",
    "plt.plot(r.history['val_loss'],label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=scaler.fit_transform(x)\n",
    "cl = pd.DataFrame(model.predict_classes(x),columns=['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class']=cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([data['id'],data['class']]).T.to_csv('Submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying Random Forest Classification\n",
    "#See https://www.datacamp.com/community/tutorials/random-forests-classifier-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9308510638297872\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.03777\n",
      "Feature: 1, Score: 0.01544\n",
      "Feature: 2, Score: 0.06358\n",
      "Feature: 3, Score: 0.03490\n",
      "Feature: 4, Score: 0.00804\n",
      "Feature: 5, Score: 0.01245\n",
      "Feature: 6, Score: 0.03201\n",
      "Feature: 7, Score: 0.10190\n",
      "Feature: 8, Score: 0.00451\n",
      "Feature: 9, Score: 0.00528\n",
      "Feature: 10, Score: 0.01496\n",
      "Feature: 11, Score: 0.00637\n",
      "Feature: 12, Score: 0.00687\n",
      "Feature: 13, Score: 0.03025\n",
      "Feature: 14, Score: 0.00361\n",
      "Feature: 15, Score: 0.00527\n",
      "Feature: 16, Score: 0.00538\n",
      "Feature: 17, Score: 0.00683\n",
      "Feature: 18, Score: 0.00376\n",
      "Feature: 19, Score: 0.00422\n",
      "Feature: 20, Score: 0.11390\n",
      "Feature: 21, Score: 0.02244\n",
      "Feature: 22, Score: 0.12549\n",
      "Feature: 23, Score: 0.14226\n",
      "Feature: 24, Score: 0.01276\n",
      "Feature: 25, Score: 0.01353\n",
      "Feature: 26, Score: 0.03320\n",
      "Feature: 27, Score: 0.11558\n",
      "Feature: 28, Score: 0.01051\n",
      "Feature: 29, Score: 0.00695\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "# get importance\n",
    "importance = clf.feature_importances_\n",
    "\n",
    "\n",
    "list = x1.columns\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()\n",
    "#pyplot.bar([x for x in range(len(importance))],importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
       "       'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
